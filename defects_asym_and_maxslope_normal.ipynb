{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folgendes uebertragen ins NB auf Arbeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDEE 2021-4-3: viell. check auf 1/omega nur auf Frequenzbereich bis zu bestimmter Grenzfrequenz (20 Hz, 50 Hz o.ae.) anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* fuer metric_hist3 (oder 2? Jedenfalls die Version, wo im Histogramm die einzelnen Fehlerarten verschiedene Farben haben) noch die Option anbieten, senkrechte Linien einzuzeichnen (unterschiedliche fuer jedes Diagramm), dann auf diese Weise die Resultate der GridSearch darstellen um zu sehen, wie gut die einzelnen Fehlerarten getrennt werden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the candidates for threshold values\n",
    "# ... beschreiben\n",
    "def get_candidates(x):\n",
    "    t2=np.sort(x)                         # sort values\n",
    "    gap = (t2[-1]-t2[0])/len(t2)          # aux. value to add elements at begin and end\n",
    "    t3 = [t2[0]-gap, *t2, t2[-1]+gap]     # append elements at begin and end\n",
    "    t4 = list(zip(t3[:-1], t3[1:]))       # aux. list for calculating the intermediate values\n",
    "    return(np.unique([(v[1]+v[0])/2 for v in t4]))   # calculate the intermediate values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificator\n",
    "# TODO: verbessern, moeglichst durch einen ersetzen, der\n",
    "#     * robuster ist (viell. mittels kde)\n",
    "#     * schnelleren Suchalgorithmus hat\n",
    "# fitcrit: criterion that should be used as optimization criterion for fit method \n",
    "class multi_threshold_classifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, ar__maxslope=np.arange(1000, 2000, 10), \n",
    "                 ar__asym=np.arange(0.01,0.03,0.001), \n",
    "                 ar__maxamp=np.arange(10000,20000,100),\n",
    "                 fitcrit='hits'):\n",
    "        \n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        self.ar__maxslope = ar__maxslope\n",
    "        self.ar__asym = ar__asym\n",
    "        self.ar__maxamp = ar__maxamp\n",
    "        self.fitcrit = fitcrit\n",
    "\n",
    "        \n",
    "    # TODO: analytisch berechnen aehnlich wie bei lin.regr., formeln ableiten\n",
    "    def fit(self, X, y):\n",
    "        ym = [el==1 for el in y]\n",
    "        # hier erstmal brut force, evtl. noch verbessern:\n",
    "        # z.B. alle columns einzeln ordnen, zwischen Nachbarwerten interpolieren und nur diese Werte als\n",
    "        # thresholds einsetzen, dann vielleicht auch viel einfacher die Werte rauszusuchen, wo z.B. die Anz. TP > Anz FP oder so\n",
    "        if self.ar__maxslope is None:\n",
    "            msls = get_candidates(X[:,0])\n",
    "            # analog die anderen\n",
    "        else:\n",
    "            msls == self.ar__maxslope\n",
    "\n",
    "        if self.ar__asym is None:\n",
    "            asys = get_candidates(X[:,1])\n",
    "            # analog die anderen\n",
    "        else:\n",
    "            asys == self.ar__asys\n",
    "\n",
    "        if self.ar__maxamp is None:\n",
    "            mams = get_candidates(X[:,2])\n",
    "            # analog die anderen\n",
    "        else:\n",
    "            mams == self.ar__maxamp\n",
    "            \n",
    "        res = list()\n",
    "        if fitcrit == 'hits':\n",
    "            for msl in msls:\n",
    "                for asy in asys:\n",
    "                    for mam in mams:\n",
    "                        y_pred = (X[:,0] >= msl) | (X[:,1]>=asy) | (X[:,2] <= mam)\n",
    "                        res.append(msl, asy, mam, sum(y_pred==ym))\n",
    "            df = pd.DataFrame.from_records(res, columns = ['maxslope', 'asym', 'maxamp', 'accur'])    \n",
    "            im = df.loc[:, 'accur'].idxmax()\n",
    "                    \n",
    "            self.thres__maxslope = df.loc[im, 'maxslope']\n",
    "            self.thres__asym = df.loc[im, 'asym']\n",
    "            self.thres__maxamp == df.loc[im, 'maxamp']\n",
    "\n",
    "        else:\n",
    "            print('noch nicht implementiert')\n",
    "            df = pd.DataFrame()\n",
    "                \n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "    #def _meaning(self, x):\n",
    "    #    # returns True/False according to fitted classifier\n",
    "    #    # notice underscore on the beginning\n",
    "    #    y = (X[:,0] >= thres__maxslope) | (X[:,1]>=thres__asym) | (X[:,2] <= thres__maxamp)\n",
    "    # \n",
    "    #    return( True if x >= self.treshold_ else False )\n",
    "    #\n",
    "    #def predict(self, X, y=None):\n",
    "    #    try:\n",
    "    #        getattr(self, \"treshold_\")\n",
    "    #    except AttributeError:\n",
    "    #        raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "    #    return([self._meaning(x) for x in X])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    X must contain three columns (in the following order):\n",
    "        1. maxslope-values\n",
    "        2. asym-values\n",
    "        3. maxamp-values\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            getattr(self, \"thres__maxslope\")\n",
    "            getattr(self, \"thres__asym\")\n",
    "            getattr(self, \"thres__maxamp\")\n",
    "            \n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        \n",
    "        y = (X[:,0] >= thres__maxslope) | (X[:,1]>=thres__asym) | (X[:,2] <= thres__maxamp)\n",
    "        return(y)\n",
    "    \n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return(sum(y==self.predict(X)))\n",
    "\n",
    "    \n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        return(sum(y_test==y_pred)/len(y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Damit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(df.loc[:, ['maxslope', 'asym', 'maxamp']].values, 3, test_size=0.5, random_state=0)\n",
    ">>> len(sss)\n",
    "3\n",
    ">>> print(sss)       \n",
    "StratifiedShuffleSplit(labels=[0 0 1 1], n_iter=3, ...)\n",
    ">>> for train_index, test_index in sss:\n",
    "...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...    X_train, X_test = X[train_index], X[test_index]\n",
    "...    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-103df3320649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split the dataset in two equal parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Set the parameters by cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m tuned_parameters = [{'thres__maxslope': linspace(2000, 10000,10),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'ar__maxslope': linspace(2000, 10000,10),\n",
    "                     'ar__asym': np.linspace(1e-5, 1e-4, 1e-5),\n",
    "                     'ar__maxamp': np.linspace(1000,2000,10)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['precision', 'recall', 'F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print(f\"Tuning hyper-parameters for {score}\")\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bladecontrol plotting style.\n",
      "Registering webvis-style.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\w012028\\repositories\\python\\von_sebastianbitzer\\wms-python\\wms\\analysis\\classification.py:13: UserWarning: xgboost package could not be imported! You will only be able to preprocess data!\n",
      "  warnings.warn(\"xgboost package could not be imported! \"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pathlib\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from wms.dbs import pit, csv, weadbs, preferences\n",
    "from wms.analysis import classification as clf\n",
    "\n",
    "from wms.dbs.csv import nbatct as nbct\n",
    "from wms.defects import asym, maxslope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check asymmetry for CtR sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stvars = ['azimuth_mean', 'azimuth_sigma', 'omega_mean', 'omega_sigma', \n",
    "          'pitch_mean', 'pitch_sigma', 'power_mean', 'power_sigma',\n",
    "          'temperature_mean', 'wind_mean', 'wind_sigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels(db, cycinfo, isdefect, channel, metric, y='wind_mean', ax=None):\n",
    "    cycinfo = cycinfo.loc(db)\n",
    "    isdefect = isdefect.loc(db)\n",
    "    \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    \n",
    "    data = cycinfo.st[y] if y in cycinfo.st else cycinfo.se[(channel, metric)]\n",
    "    ax = data.plot(lw=1, color='0.6', label=metric if y is None else y, ax=ax)\n",
    "    \n",
    "    if y is None:\n",
    "        if metric == 'maxslope':\n",
    "            ax.set_yscale('log')\n",
    "        ax.set_ylabel(metric)\n",
    "    else:\n",
    "        ax.set_ylabel(y)\n",
    "        \n",
    "    data[isdefect.se[(channel, metric)] == 1].plot(\n",
    "        ax=ax, style='.k', label='defect')\n",
    "    data[isdefect.se[(channel, metric)] == 0].plot(\n",
    "        ax=ax, style='.', color='tab:cyan', label='normal')\n",
    "    \n",
    "    ax.set_title(f'{db}\\n{metric} defect labels for {channel}')\n",
    "    ax.get_figure().tight_layout()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "def nbct(db, ct, nb=1, days=1):\n",
    "    ct = pd.Timestamp(ct)\n",
    "    \n",
    "    if nb == 0:\n",
    "        return ct\n",
    "    elif nb > 0:\n",
    "        cts = weadbs.cdef_query(\n",
    "            db, cycle='hour', where={\n",
    "                'create_time': (ct + pd.Timedelta(minutes=1), ct + pd.Timedelta(days=days)),\n",
    "                'available_data': {2, 3}},\n",
    "            columns=['create_time', 'ID', 'available_data'])\n",
    "    else:\n",
    "        nb = -nb\n",
    "        cts = weadbs.cdef_query(\n",
    "            db, cycle='hour', where={\n",
    "                'create_time': (ct - pd.Timedelta(days=days), ct),\n",
    "                'available_data': {2, 3}},\n",
    "            columns=['create_time', 'ID', 'available_data']).sort_index(ascending=False)\n",
    "    \n",
    "    if cts.empty:\n",
    "        return pd.NaT\n",
    "    \n",
    "    atcts = cts[cts.available_data == 3]\n",
    "    if not atcts.empty:\n",
    "        if nb <= atcts.shape[0]:\n",
    "            return atcts.create_time.iloc[nb - 1]\n",
    "        else:\n",
    "            return pd.NaT\n",
    "    \n",
    "    nextat = pd.NaT\n",
    "    for cycle in cts.itertuples():\n",
    "        at = csv.load_at_dir(db, cycle.create_time, cycle.ID, oris=['edge'], blades=[1])\n",
    "        if not at.empty:\n",
    "            nb -= 1\n",
    "            if nb == 0:\n",
    "                nextat = cycle.create_time\n",
    "                break\n",
    "    \n",
    "    return nextat\n",
    "\n",
    "\n",
    "def check_at(cycinfo, db, ct, ori='edge', blades=(1, 2, 3), with_diff=True,\n",
    "             labelmetrics=['maxslope', 'asym95_m0std1_split'], fig=None, axes=None):\n",
    "    st = weadbs.cdef_query(db, cycle='hour', where={'create_time': ct},\n",
    "                           columns=stvars + ['create_time', 'ID']).loc[0]\n",
    "    \n",
    "    tdata = csv.load_at_dir(db, ct, int(st.ID),\n",
    "                            oris=(ori,) if isinstance(ori, str) else ori, \n",
    "                            blades=blades).astype(float)\n",
    "    if tdata.empty:\n",
    "        print('No AT-data!')\n",
    "        return axes\n",
    "    \n",
    "    if cycinfo.se.index.nlevels == 2:\n",
    "        cycinfo = cycinfo.loc(db)\n",
    "    try:\n",
    "        metrics = cycinfo.se.loc[ct]\n",
    "    except KeyError:\n",
    "        metrics = None\n",
    "        \n",
    "    stinfo = (f'\\nomega = {st.omega_mean:.3f}, power = {st.power_mean:.0f}, '\n",
    "              f'pitch = {st.pitch_mean:.0f}, wind = {st.wind_mean:.1f}')\n",
    "    \n",
    "    if axes is None:\n",
    "        if fig is None:\n",
    "            fig, _ = plt.subplots(\n",
    "                1 + with_diff, 1, sharex=True, figsize=(7.8, 7 if with_diff else 5),\n",
    "                squeeze=False)\n",
    "        else:\n",
    "            if fig.axes:\n",
    "                for ax in fig.axes[:1 + with_diff]:\n",
    "                    ax.clear()\n",
    "            else:\n",
    "                axes = fig.subplots(\n",
    "                    1 + with_diff, 1, sharex=True, squeeze=False)\n",
    "        \n",
    "        axes = fig.axes\n",
    "        \n",
    "    ax = axes[0]\n",
    "    ax = tdata.plot(lw=1, ax=ax)\n",
    "    \n",
    "    ax.set_title(f'{db} - {ct}{stinfo}')\n",
    "    \n",
    "    legend = []\n",
    "    for ch in tdata.columns:\n",
    "        label = ch\n",
    "        if metrics is not None:\n",
    "            label = f'{label}: ' + ', '.join(\n",
    "                [f'{m:.2f}' for m in metrics.xs(ch)[labelmetrics]])\n",
    "        legend.append(label)\n",
    "    ltitle = '' if metrics is None else '\\n'.join(labelmetrics)\n",
    "            \n",
    "    ax.set_ylabel('amplitude (digits)')\n",
    "    \n",
    "    if with_diff:\n",
    "        ax = tdata.diff().plot(lw=1, ax=axes[1])\n",
    "        ax.set_ylabel('diff (digits)')\n",
    "    \n",
    "    ax.legend(legend, title=ltitle)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return axes\n",
    "\n",
    "\n",
    "def check_af(cycinfo, db, ct, ori='edge', blades=(1, 2, 3), fband=(2, 10), log=False,\n",
    "             fig=None, ax=None):\n",
    "    if cycinfo.st.index.nlevels == 2:\n",
    "        cycinfo = cycinfo.loc(db)\n",
    "    try:\n",
    "        st = cycinfo.st.loc[ct]\n",
    "    except KeyError:\n",
    "        st = weadbs.cdef_query(db, cycle='hour', where={'create_time': ct},\n",
    "                               columns=stvars + ['create_time', 'ID']).loc[0]\n",
    "        \n",
    "    stinfo = (f'\\nomega = {st.omega_mean:.3f}, power = {st.power_mean:.0f}, '\n",
    "              f'pitch = {st.pitch_mean:.0f}, wind = {st.wind_mean:.1f}')\n",
    "    \n",
    "    if ax is None:\n",
    "        if fig is None:\n",
    "            fig, ax = plt.subplots(constrained_layout=True)\n",
    "        else:\n",
    "            if fig.axes:\n",
    "                ax = fig.axes[0]\n",
    "                ax.clear()\n",
    "            else:\n",
    "                ax = fig.subplots()\n",
    "    \n",
    "    af = csv.load_af(db, ct, int(st.ID), chform='{blade}_{ori}',\n",
    "                     oris=(ori,) if isinstance(ori, str) else ori, blades=blades)\n",
    "    \n",
    "    if not af.empty:\n",
    "        af = af.unstack('channel').loc[slice(*fband)].sort_index(axis=1)\n",
    "        af.loc[slice(*fband)].plot(ax=ax)\n",
    "\n",
    "        ax.set_title(f'{db} - {ct}{stinfo}')\n",
    "        ax.set_ylabel('amplitude (digits)')\n",
    "\n",
    "        if log:\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylim(af.stack().min(), ax.get_ylim()[1])\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precompiled data and information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precalculated metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycpath = 'defect_metrics_acc_normal__since2014_v4.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tables'.  Use pip or conda to install tables.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-01d84df40b49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcycpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrdbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mctrdbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctrdbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dbname'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcycpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\sensor_defect5\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format is not a defined argument for HDFStore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_complibs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\sensor_defect5\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'tables'.  Use pip or conda to install tables."
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(cycpath, 'r') as store:\n",
    "    _, ctrdbs, _ = next(store.walk())\n",
    "    ctrdbs = pd.Index(ctrdbs, name='dbname')\n",
    "    \n",
    "options = pd.read_hdf(cycpath, 'options').to_dict()\n",
    "where_data = eval(pd.read_hdf(cycpath, 'where')['where'])\n",
    "    \n",
    "cycinfo = weadbs.SEData.concat(\n",
    "    [weadbs.SEData.from_hdf(cycpath, prefix=db) for db in ctrdbs],\n",
    "    keys=ctrdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infos about turbines and tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets = pd.read_pickle(\"df_tickets.pkl\")\n",
    "df_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load turbine infos of turbines contained in precalculated metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weainfo = pit.query_pit(\n",
    "    f\"\"\"SELECT Datenbankname, WEA_Typ#Name, WEA_Name, Windpark_WEA#Windparkname\n",
    "        FROM VIEW_Windkraftanlagen \n",
    "        WHERE Datenbankname in ({', '.join(['%s'] * ctrdbs.size)})\"\"\",\n",
    "    tuple(ctrdbs)).set_index('Datenbankname')\n",
    "\n",
    "weainfo['N'] = cycinfo.se.groupby(level='dbname').size()\n",
    "weainfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display infos about precalculated metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cycinfo.se\n",
    "#data = cycinfo.select_st().se.stack('channel')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to label the time series of df on behalf of the defect periods given in dict_tickets, it returns the indices of that data sets that are within the sensor defect times\n",
    "def label_metrics_data(cycinfo, df_tickets):\n",
    "    #sfmt = '%Y-%m-%d %H:%M:%S'\n",
    "    res = dict()\n",
    "    res_ix_list = list()\n",
    "    for idx, row in df_tickets.iterrows():\n",
    "        db = row['db']\n",
    "        ticket_id = row['ticket_id']\n",
    "        defect_times = row['defect_times']  \n",
    "        \n",
    "        data = cycinfo.loc(db).se.drop_duplicates().index\n",
    "        \n",
    "        for ch, pers in defect_times.items():\n",
    "            ixs = list()\n",
    "            for per in pers:\n",
    "                if len(per)==1:\n",
    "                    cts = (data[data >= per[0]])\n",
    "                else:\n",
    "                    cts = (data[(data >= per[0]) & (data<per[1])])\n",
    "                ixs.append(cts)\n",
    "                [res_ix_list.append((db, ct, ch)) for ct in cts]\n",
    "            res.update({(db, ch): ixs})\n",
    "            \n",
    "    res_ix = pd.MultiIndex.from_tuples(res_ix_list, names=['dbname', 'create_time', 'channel'])\n",
    "    return res, res_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_times_by_type = dict()\n",
    "for g, dfg in df_tickets.groupby('defecttype'):\n",
    "    _ddt, idt = label_metrics_data(cycinfo, dfg)\n",
    "    defect_times_by_type.update({g: idt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_defect_times, idx_defect_times = label_metrics_data(cycinfo, df_tickets)\n",
    "#dict_defect_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_defect_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By sensor orientation and operational state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only start at 3 m/s wind, because we anyway won't be able \n",
    "# to detect ice for lower wind\n",
    "# exclude trudeln for now by selecting high pitch\n",
    "where_stand = weadbs.Where(\n",
    "    {'omega_mean': 0, \n",
    "     'power_mean': (-500, 1), \n",
    "     'wind_mean': (3,),\n",
    "     'pitch_mean': (40,)})\n",
    "\n",
    "where_betrieb = weadbs.Where(\n",
    "    {'omega_mean': (0.05,),\n",
    "     'power_mean': (1,),\n",
    "     'wind_mean': (3,)})\n",
    "\n",
    "def make_bins(opts):\n",
    "    \n",
    "    if 'xmax' in opts:\n",
    "        # original version\n",
    "        #opts.setdefault(\n",
    "        #    'bins', np.r_[np.linspace(0, opts['xmax'], opts['B']), 10000])\n",
    "        \n",
    "        # modified by CK, otherwise error occurs if xmax>10000\n",
    "        tmp = opts['xmax']\n",
    "        if tmp<10000:\n",
    "            u = 10000\n",
    "        else:\n",
    "            u = np.power(10, int(np.ceil(np.log10(tmp))+2))\n",
    "        opts.setdefault(\n",
    "            'bins', np.r_[np.linspace(0, opts['xmax'], opts['B']), u]) \n",
    "        opts.setdefault('xlim', opts['xmax'] * 1.1)\n",
    "    else:\n",
    "        opts.setdefault('bins', opts['B'])\n",
    "\n",
    "def metric_hist(cycinfo, metric, standopts={}, betriebopts={}, isdefect=None, figsize=(7.8, 6)):\n",
    "    standopts = standopts.copy()\n",
    "    standopts.setdefault('where', where_stand)\n",
    "    standopts.setdefault('B', 100)\n",
    "    standopts.setdefault('maxslopethr', 100)\n",
    "    make_bins(standopts)\n",
    "    \n",
    "    betriebopts = betriebopts.copy()\n",
    "    betriebopts.setdefault('where', where_betrieb)\n",
    "    betriebopts.setdefault('B', 100)\n",
    "    betriebopts.setdefault('maxslopethr', 800)\n",
    "    make_bins(betriebopts)\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, sharex='col', sharey='col', constrained_layout=True, figsize=figsize)\n",
    "    \n",
    "    for ori, row in zip(['edge', 'flap'], axes):\n",
    "        data = cycinfo.select_st(standopts['where'], ori).se.stack('channel')\n",
    "        if isdefect is not None:\n",
    "            ind = isdefect.select_st(standopts['where'], ori).se.stack(\n",
    "                'channel')['true'].astype(bool)\n",
    "        elif 'maxslopethr' in standopts:\n",
    "            ind = data['maxslope'] > standopts['maxslopethr']\n",
    "        else:\n",
    "            ind = None\n",
    "        \n",
    "        if ind is not None:\n",
    "            ax = sns.distplot(\n",
    "                data.loc[ind, metric], kde=False, bins=standopts['bins'],\n",
    "                ax=row[0], label='defect')\n",
    "            ax = sns.distplot(\n",
    "                data.loc[~ind, metric], kde=False, bins=standopts['bins'],\n",
    "                ax=row[0], label='normal')\n",
    "            \n",
    "            ax.legend(title='maxslope' if isdefect is None else 'true label')\n",
    "        else:\n",
    "            ax = sns.distplot(\n",
    "                data[metric], kde=False, bins=standopts['bins'], ax=row[0])\n",
    "        \n",
    "        ax.set_ylabel(f'{ori}\\ncycle count')\n",
    "        \n",
    "        data = cycinfo.select_st(betriebopts['where'], ori).se.stack('channel')\n",
    "        if isdefect is not None:\n",
    "            ind = isdefect.select_st(betriebopts['where'], ori).se.stack(\n",
    "                'channel')['true'].astype(bool)\n",
    "        elif 'maxslopethr' in betriebopts:\n",
    "            ind = data['maxslope'] > betriebopts['maxslopethr']\n",
    "        else:\n",
    "            ind = None\n",
    "        \n",
    "        if ind is not None:\n",
    "            ax = sns.distplot(\n",
    "                data.loc[ind, metric], kde=False, bins=betriebopts['bins'],\n",
    "                ax=row[1], label='defect')\n",
    "            ax = sns.distplot(\n",
    "                data.loc[~ind, metric], kde=False, bins=betriebopts['bins'],\n",
    "                ax=row[1], label='normal')\n",
    "            \n",
    "            ax.legend(title='maxslope' if isdefect is None else 'true label')\n",
    "        else:    \n",
    "            ax = sns.distplot(\n",
    "                data[metric], kde=False, bins=betriebopts['bins'], ax=row[1])\n",
    "        \n",
    "    for ax in axes[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "    axes[0, 0].set_title('stand')\n",
    "    axes[0, 1].set_title('betrieb')\n",
    "    if 'xlim' in standopts:\n",
    "        axes[0, 0].set_xlim(0, standopts['xlim'])\n",
    "    if 'xlim' in betriebopts:\n",
    "        axes[0, 1].set_xlim(0, betriebopts['xlim'])\n",
    "    \n",
    "    return axes\n",
    "\n",
    "\n",
    "# new variant 2021-3-18, defect/ok as parameter, not determined by max_slope\n",
    "def metric_hist2(cycinfo, metric, idx_defect_times, standopts={}, betriebopts={}, figsize=(7.8, 6)):\n",
    "    standopts = standopts.copy()\n",
    "    standopts.setdefault('where', where_stand)\n",
    "    #standopts.setdefault('B', 100)\n",
    "    #standopts.setdefault('maxslopethr', 100)\n",
    "    make_bins(standopts)\n",
    "    \n",
    "    betriebopts = betriebopts.copy()\n",
    "    betriebopts.setdefault('where', where_betrieb)\n",
    "    #betriebopts.setdefault('B', 100)\n",
    "    #betriebopts.setdefault('maxslopethr', 800)\n",
    "    make_bins(betriebopts)\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, sharex='col', sharey='col', constrained_layout=True, figsize=figsize)\n",
    "    \n",
    "    for ori, row in zip(['edge', 'flap'], axes):\n",
    "        data = cycinfo.select_st(standopts['where'], ori).se.stack('channel').drop_duplicates()\n",
    "                \n",
    "        if idx_defect_times is not None:\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            not_ind = data.index.difference(idx_defect_times)\n",
    "            ax = sns.distplot(\n",
    "                data.loc[ind, metric], kde=False, bins=standopts['bins'],\n",
    "                ax=row[0], label='defect')\n",
    "            ax = sns.distplot(\n",
    "                data.loc[not_ind, metric], kde=False, bins=standopts['bins'],\n",
    "                ax=row[0], label='normal')\n",
    "            \n",
    "            ax.legend(title='true label')\n",
    "        else:\n",
    "            ax = sns.distplot(\n",
    "                data[metric], kde=False, bins=standopts['bins'], ax=row[0])\n",
    "        \n",
    "        ax.set_ylabel(f'{ori}\\ncycle count')\n",
    "        \n",
    "        data = cycinfo.select_st(betriebopts['where'], ori).se.stack('channel').drop_duplicates()\n",
    "        \n",
    "        if idx_defect_times is not None:\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            not_ind = data.index.difference(idx_defect_times)\n",
    "            ax = sns.distplot(\n",
    "                data.loc[ind, metric], kde=False, bins=betriebopts['bins'],\n",
    "                ax=row[1], label='defect')\n",
    "            ax = sns.distplot(\n",
    "                data.loc[not_ind, metric], kde=False, bins=betriebopts['bins'],\n",
    "                ax=row[1], label='normal')\n",
    "            \n",
    "            ax.legend(title='true label')\n",
    "        else:    \n",
    "            ax = sns.distplot(\n",
    "                data[metric], kde=False, bins=betriebopts['bins'], ax=row[1])\n",
    "        \n",
    "    for ax in axes[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "    axes[0, 0].set_title('stand')\n",
    "    axes[0, 1].set_title('betrieb')\n",
    "    if 'xlim' in standopts:\n",
    "        axes[0, 0].set_xlim(0, standopts['xlim'])\n",
    "    if 'xlim' in betriebopts:\n",
    "        axes[0, 1].set_xlim(0, betriebopts['xlim'])\n",
    "    \n",
    "    return axes\n",
    "\n",
    "\n",
    "\n",
    "# new variant 2021-3-27, defect/ok as parameter, not determined by max_slope\n",
    "def metric_hist3(cycinfo, metric, defect_times_by_type, standopts={}, betriebopts={}, figsize=(7.8, 6)):\n",
    "    standopts = standopts.copy()\n",
    "    standopts.setdefault('where', where_stand)\n",
    "    #standopts.setdefault('B', 100)\n",
    "    #standopts.setdefault('maxslopethr', 100)\n",
    "    make_bins(standopts)\n",
    "    \n",
    "    betriebopts = betriebopts.copy()\n",
    "    betriebopts.setdefault('where', where_betrieb)\n",
    "    #betriebopts.setdefault('B', 100)\n",
    "    #betriebopts.setdefault('maxslopethr', 800)\n",
    "    make_bins(betriebopts)\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, sharex='col', sharey='col', constrained_layout=True, figsize=figsize)\n",
    "    \n",
    "    for ori, row in zip(['edge', 'flap'], axes):\n",
    "        data = cycinfo.select_st(standopts['where'], ori).se.stack('channel').drop_duplicates()\n",
    "        not_ind = data.index\n",
    "        for deftype, idx_defect_times in defect_times_by_type.items():\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            #not_ind = data.index.difference(idx_defect_times)\n",
    "            not_ind = not_ind.difference(idx_defect_times)\n",
    "            ax = sns.distplot(data.loc[ind, metric], kde=False, bins=standopts['bins'], ax=row[0], label=defect_type)\n",
    "        ax = sns.distplot(data.loc[not_ind, metric], kde=False, bins=standopts['bins'], ax=row[0], label='normal')\n",
    "            \n",
    "        ax.legend(title='true label')\n",
    "        #else:\n",
    "        #    ax = sns.distplot(\n",
    "        #        data[metric], kde=False, bins=standopts['bins'], ax=row[0])\n",
    "        \n",
    "        ax.set_ylabel(f'{ori}\\ncycle count')\n",
    "        \n",
    "        data = cycinfo.select_st(betriebopts['where'], ori).se.stack('channel').drop_duplicates()\n",
    "        not_ind = data.index\n",
    "        for def_type, idx_defect_times in def_times_by_type.items():\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            #not_ind = data.index.difference(idx_defect_times)\n",
    "            not_ind = not_ind.difference(idx_defect_times)\n",
    "            ax = sns.distplot(data.loc[ind, metric], kde=False, bins=betriebopts['bins'], ax=row[1], label=def_type)\n",
    "        ax = sns.distplot(data.loc[not_ind, metric], kde=False, bins=betriebopts['bins'], ax=row[1], label='normal')\n",
    "        ax.legend(title='true label')\n",
    "        \n",
    "    for ax in axes[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "    axes[0, 0].set_title('stand')\n",
    "    axes[0, 1].set_title('betrieb')\n",
    "    if 'xlim' in standopts:\n",
    "        axes[0, 0].set_xlim(0, standopts['xlim'])\n",
    "    if 'xlim' in betriebopts:\n",
    "        axes[0, 1].set_xlim(0, betriebopts['xlim'])\n",
    "    \n",
    "    return axes\n",
    "\n",
    "\n",
    "\n",
    "# create boxplots for all defect types\n",
    "def metric_box(cycinfo, metric, defect_times_by_type, standopts={}, betriebopts={}, figsize=(7.8, 6)):\n",
    "    standopts = standopts.copy()\n",
    "    standopts.setdefault('where', where_stand)\n",
    "    #standopts.setdefault('B', 100)\n",
    "    #standopts.setdefault('maxslopethr', 100)\n",
    "    make_bins(standopts)\n",
    "    \n",
    "    betriebopts = betriebopts.copy()\n",
    "    betriebopts.setdefault('where', where_betrieb)\n",
    "    #betriebopts.setdefault('B', 100)\n",
    "    #betriebopts.setdefault('maxslopethr', 800)\n",
    "    make_bins(betriebopts)\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, sharex='col', sharey='col', constrained_layout=True, figsize=figsize)\n",
    "    \n",
    "    for ori, row in zip(['edge', 'flap'], axes):\n",
    "        data = cycinfo.select_st(standopts['where'], ori).se.stack('channel').drop_duplicates().assign(deftype='ok')\n",
    "        for deftype, idx_defect_times in defect_times_by_type.items():\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            data.loc[ind, 'deftype'] = deftype\n",
    "            \n",
    "        sns.boxplot(data=data, x='deftype', y=metric, ax=ax)\n",
    "        ax.set_ylabel(f'{ori}\\ncycle count')\n",
    "        \n",
    "        data = cycinfo.select_st(betriebopts['where'], ori).se.stack('channel').drop_duplicates().assign(deftype='ok')\n",
    "        for def_type, idx_defect_times in def_times_by_type.items():\n",
    "            ind = data.index.intersection(idx_defect_times)\n",
    "            data.loc[ind, 'deftype'] = deftype\n",
    "            \n",
    "        sns.boxplot(data=data, x='deftype', y=metric, ax=ax)\n",
    "        ax.set_ylabel(f'{ori}\\ncycle count')\n",
    "        \n",
    "    for ax in axes[0, :]:\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "    axes[0, 0].set_title('stand')\n",
    "    axes[0, 1].set_title('betrieb')\n",
    "    if 'xlim' in standopts:\n",
    "        axes[0, 0].set_xlim(0, standopts['xlim'])\n",
    "    if 'xlim' in betriebopts:\n",
    "        axes[0, 1].set_xlim(0, betriebopts['xlim'])\n",
    "    \n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histopts = {\n",
    "    'maxslope': {'standopts': {'xmax': 33000}, 'betriebopts': {'xmax': 33000}},\n",
    "    #'asym95_std1': {'standopts': {'xmax': 6}, 'betriebopts': {'xmax': 6}},\n",
    "    #'asym95_m0std1': {'standopts': {'xmax': 6}, 'betriebopts': {'xmax': 6}},\n",
    "    'asym95_m0std1_split': {'standopts': {'xmax': 3.5}, 'betriebopts': {'xmax': 3.5}},\n",
    "    'max_amp': {'standopts': {'xmax': 12000}, 'betriebopts': {'xmax': 33000}}#,\n",
    "    #'se': {'standopts': {'xmax': 1000}, 'betriebopts': {'xmax': 3000}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _metric, _opts in histopts.items():\n",
    "    display(Markdown('### ' + _metric))\n",
    "    #axes = metric_hist2(cycinfo, _metric, idx_defect_times, **_opts)\n",
    "    axes = metric_hist3(cycinfo, _metric, defect_times_by_type, **_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By turbine and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chs_edge = ['101_edge', '102_edge', '103_edge']\n",
    "chs_flap = ['101_flap', '102_flap', '103_flap']\n",
    "chs_all = np.r_[chs_edge, chs_flap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hists_by_db(df_tickets, cycinfo, metric, opwhere=dict(), chs = chs_all, bins=np.r_[np.linspace(0,30000,100), 40000], xlim = [-10, 20000]):\n",
    "\n",
    "    ctrdbs = df_tickets.db.unique()\n",
    "    cp = sns.color_palette(\"Paired\")\n",
    "    cp2 = [cp[i] for i in [5,4,1,0,3,2]]    \n",
    "    \n",
    "    fig, axes = plt.subplots(ctrdbs.size, 1, sharex=True, constrained_layout=True,\n",
    "                             figsize=(9.3, max(4, 2 * ctrdbs.size)))\n",
    "\n",
    "    for ax, _db in zip(axes, ctrdbs):\n",
    "        df = df_tickets[df_tickets.db==_db].loc[:, ['defect_times', 'defecttype']]\n",
    "        for _idx, row in df.iterrows():\n",
    "            sinfo = \",\".join(row['defect_times'].keys()) + f\": {row['defecttype']}\"\n",
    "        \n",
    "        _data = cycinfo.select_st(opwhere).se.loc[_db].xs(metric, axis=1, level=1, drop_level=True).drop_duplicates()\n",
    "        if not _data.empty:\n",
    "            sns.histplot(data=_data, ax=ax, kde=True, legend=True, bins=bins, palette = cp2)\n",
    "            #sns.displot(data=_data, ax=ax, kde=False)#, bins=np.r_[np.linspace(0, 1000, 100), 100000])#, hue=, row=None, col=None, weights=None, kind='hist', rug=False, rug_kws=None, log_scale=None, legend=True, palette=None, hue_order=None, hue_norm=None, color=None, col_wrap=None, row_order=None, col_order=None, height=5, aspect=1, facet_kws=None, **kwargs)Â¶\n",
    "#                             bins=np.r_[np.linspace(0, 1000, 100), 10000])\n",
    "\n",
    "        #ax.legend()\n",
    "        ax.set_ylabel(_db)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_title(sinfo, y=0.85, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max-slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists_by_db(df_tickets, cycinfo, 'maxslope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weitere Darstellungen anfertigen:\n",
    "    - aufgespalten nach stand/betrieb\n",
    "    - aufgespalten nach edge/flap \n",
    "    - aufgespalten nach defekt/ok\n",
    "\n",
    "Dabei herausfinden:\n",
    "    - was sind sinnvolle Schwellwerte fuer Stand und Betrieb, edge und flap\n",
    "    - uebriggebliebene Defekte nach den jeweils anderen Metriken darstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists_by_db(df_tickets, cycinfo, 'max_amp', bins=np.r_[np.linspace(0,3000,100), 4000], xlim=[-10, 2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists_by_db(df_tickets, cycinfo, 'asym95_m0std1_split', bins=np.arange(0, 3.5, 0.05), xlim = [0, 3.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "* inkonsistent aussehende Kanaele durchgehen und weglassen, re-labeln o.ae.\n",
    "* jeweils 1 Diagramm fuer (stand,betrieb) x (edge,flap) x metrics anfertigen:\n",
    "    \n",
    "    * Boxplots fuer ok, kurzschluss, offener kanal usw. nebeneinander darstellen\n",
    "    * Histogramme fuer ok, Kurzschluss, offener Kanal usw. nebeneinander darstellen\n",
    "    \n",
    "* aus unabhaengig voneinander bestimmten Werte F1, false positives etc. fuer jede einzelne Defektform und insgesamt berechnen und darstellen\n",
    "* pipeline bauen, Parameter in Kombination ermitteln fuer jede WEA einzeln und insgesamt\n",
    "* mit unabhaengig voneinander ermittelten Parametern vgl.n nebeneinander\n",
    "* false positives/true negatives getrennt betrachten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2021-3-23: alle Daten (se, st, tickest) kombinieren um einen Dataframe mit Betriebszustaenden, Metriken und Defekttyp zu erzeugen fuer einfachere Erstellung von Boxplots etc. Dazu se wide to long, mit st joinen, durch df_tickets durchgehen und ok/Defekttyp eintragen    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = cycinfo.se.drop_duplicates().reset_index().head()\n",
    "print(df_se)\n",
    "pd.melt(df_se, id_vars='date', value_vars=['AA', 'BB', 'CC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycinfo.st.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cycinfo.se.drop_duplicates().merge(cycinfo.st.drop_duplicates(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycinfo.st.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile-based thresholds and relation between metrics\n",
    "### q-values corresponding to maxslope thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxslope_thresh = {'stand': 100, 'betrieb': 800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for opstate, opwhere in zip(['stand', 'betrieb'], [where_stand, where_betrieb]):\n",
    "    _qval = (cycinfo.select_st(opwhere).se.stack('channel')['maxslope'] \n",
    "             < maxslope_thresh[opstate]).mean()\n",
    "    print(f'{opstate}: {_qval:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% quantile thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = pd.DataFrame(\n",
    "    dtype=float, columns=pd.Index(['stand', 'betrieb'], name='opstate'),\n",
    "    index=cycinfo.se.columns.levels[1].set_names('metric'))\n",
    "\n",
    "isdefect = weadbs.SEData(cycinfo.se.applymap(lambda v: -1), cycinfo.st)\n",
    "\n",
    "for opstate, opwhere in zip(thresholds.columns, (where_stand, where_betrieb)):\n",
    "    _metrics = cycinfo.select_st(opwhere)\n",
    "    thresholds.loc[:, opstate] = _metrics.se.stack('channel').quantile(0.95)\n",
    "    \n",
    "    # overwrite maxslope thresholds with agreed upon values\n",
    "    thresholds.loc['maxslope', opstate] = maxslope_thresh[opstate]\n",
    "    \n",
    "    # overwrite asym95_m0std1_split thresholds with values giving low FPs\n",
    "    thresholds.loc['asym95_m0std1_split', opstate] = 1.1 if opstate == 'betrieb' else 0.7\n",
    "    \n",
    "    isdefect.se.loc[_metrics.se.index, :] = cycinfo.se.loc[_metrics.se.index, :].apply(\n",
    "        lambda s: s > thresholds.loc[s.name[1], opstate]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between classifications based on the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = isdefect.se.stack('channel').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "\n",
    "img = ax.matshow(corrs)\n",
    "ax.grid(False)\n",
    "ax.set_yticks(np.arange(corrs.shape[0]))\n",
    "ax.set_yticklabels(corrs.index)\n",
    "ax.set_xticklabels([]);\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall fraction of cycles identified by maxslope that are also identified by the other metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdefect_stack = isdefect.se.stack('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdefect_stack.agg(lambda s: (s[isdefect_stack.maxslope == 1] == 1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lametta example\n",
    "- note: from cycle 2020-08-03 13:04:00 to cycle 2020-08-04 08:34:33 (both inclusive) either omega_mean has None, or, even more odd, the AT-data stored for this turbine is obviously from an acceleration sensor and not from a strain sensor - so this is mixed up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_bc_t_02395_strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('maxslope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('asym95_m0std1_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_isd = isdefect.loc(isdefect.se.iloc[:, 0] >= 0).loc(db).se\n",
    "\n",
    "ytrue = _isd.applymap(lambda v: 0)\n",
    "ytrue['102_edge'] = 1\n",
    "ytrue['102_flap'] = 1\n",
    "\n",
    "_isd = _isd.stack('channel')\n",
    "ytrue = ytrue.stack('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.concat(\n",
    "    [clf.BinScores(ytrue[metric], _isd[metric]).to_series()\n",
    "     for metric in ytrue.columns], axis=1, keys=ytrue.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "ax = scores.loc['F1'].plot.bar(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard example\n",
    "- in all cycles before 2020-04 blade 3, flap has a flat signal with small jumps / spikes up and down from time to time; maxslope only picks up on these jumps, when they pass threshold; asym95_m0std1_split recognises all of these cycles as defects, because the short jumps (in time) lead to an asymmetric raw AT signal; asym with amax1, or skew don't recognise these cycles consistently either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_vid_v231228'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_period = slice(None, '2020-07-25 13:12:54')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).loc(defect_period).plot_se('maxslope')\n",
    "axes[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).loc(defect_period).plot_se('asym95_m0std1_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = isdefect.loc(isdefect.se.iloc[:, 0] >= 0).se.loc[\n",
    "    (db, defect_period), :]\n",
    "\n",
    "ytrue = ytest.xs('maxslope', axis=1, level=1).applymap(lambda v: 0)\n",
    "ytrue['103_flap'] = 1\n",
    "\n",
    "ytest = ytest.stack('channel')\n",
    "ytrue = ytrue.stack('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.concat(\n",
    "    [clf.BinScores(ytrue, ytest[metric]).to_series()\n",
    "     for metric in ytest.columns], axis=1, keys=ytest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "ax = scores.loc['F1'].plot.bar(ax=ax)\n",
    "ax.set_ylabel('F1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to maxslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxslope_FN = ytest[(ytrue == 1) & (ytest.maxslope == 0)]\n",
    "maxslope_TN = ytest[(ytrue == 0) & (ytest.maxslope == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex=True, constrained_layout=True, figsize=(5, 5))\n",
    "\n",
    "ax = (maxslope_FN).sum().plot.bar(ax=axes[0])\n",
    "ax.set_ylabel('# corrected FN')\n",
    "ax = (maxslope_TN).sum().plot.bar(ax=axes[1])\n",
    "ax.set_ylabel('# new FP');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination with maxslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_combined = ytest.apply(lambda s: s | ytest.maxslope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_combined = pd.concat(\n",
    "    [clf.BinScores(ytrue, ytest_combined[metric]).to_series()\n",
    "     for metric in ytest.columns], axis=1, keys=ytest_combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "ax = scores_combined.loc['F1'].plot.bar(ax=ax)\n",
    "ax.set_ylabel('F1');\n",
    "ax.set_ylim(0.5, 0.75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ind = ytrue[ytest_combined['asym95_m0std1_split'] != ytrue].unstack('channel')['103_flap'].dropna().index.get_level_values('create_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'flap'\n",
    "_ct = nbct(db, '2020-07-24 18:03:12', nb=0, days=12)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)\n",
    "cycinfo.se.loc[(db, _ct), '103_flap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metric(ytrue, cycinfo, metric, threshs, opstate='betrieb', ybase=None):\n",
    "    ytrue = ytrue.unstack('channel')\n",
    "    \n",
    "    values = cycinfo.loc(ytrue.index).select_st(\n",
    "        where_betrieb if opstate == 'betrieb' else where_stand).se.xs(\n",
    "            metric, axis=1, level=1)\n",
    "    ytrue = ytrue.loc[values.index].stack('channel')\n",
    "    \n",
    "    if ybase is not None:\n",
    "        ybase = ybase.unstack('channel').loc[values.index].stack('channel')\n",
    "    \n",
    "    scores = []\n",
    "    for thr in threshs:\n",
    "        ytest = (values > thr).stack()\n",
    "        if ybase is not None:\n",
    "            ytest = ytest | ybase.astype(bool)\n",
    "            \n",
    "        _scores = clf.BinScores(ytrue, ytest.astype(int)).to_series()\n",
    "        _scores['FP'] = _scores['FPR'] * (ytrue == 0).sum()\n",
    "        _scores['TP'] = _scores['recall'] * (ytrue == 1).sum()\n",
    "        \n",
    "        scores.append(_scores)\n",
    "        \n",
    "    return pd.concat(scores, keys=threshs, axis=1).T, ytrue.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(_ind).to_csv(f'{db}_103_flap_undetected_defects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = 'asym95_m0std1_split'\n",
    "_base_metric = 'maxslope'\n",
    "_thrs = np.r_[np.arange(0, 2.01, 0.02), np.arange(2.5, 3.5, 0.5)]\n",
    "\n",
    "scores_betrieb_base, N_betrieb = score_metric(\n",
    "    ytrue, cycinfo, _base_metric, [thresholds.loc[_base_metric, 'betrieb']])\n",
    "scores_stand_base, N_stand = score_metric(\n",
    "    ytrue, cycinfo, _base_metric, [thresholds.loc[_base_metric, 'stand']], 'stand')\n",
    "\n",
    "scores_betrieb, N_betrieb = score_metric(\n",
    "    ytrue, cycinfo, _metric, _thrs, ybase=ytest[_base_metric])\n",
    "scores_stand, N_stand = score_metric(\n",
    "    ytrue, cycinfo, _metric, _thrs, 'stand', ybase=ytest[_base_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_betrieb_base['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "(scores_stand['TP'] - scores_stand_base['TP'].iloc[0]).plot(\n",
    "    ax=ax, label='additional TP')\n",
    "(scores_stand['FP'] - scores_stand_base['FP'].iloc[0]).plot(\n",
    "    ax=ax, label='additional FP')\n",
    "\n",
    "ax.set_title('stand')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('# cycles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "(scores_betrieb['TP'] - scores_betrieb_base['TP'].iloc[0]).plot(\n",
    "    ax=ax, label='additional TP')\n",
    "(scores_betrieb['FP'] - scores_betrieb_base['FP'].iloc[0]).plot(\n",
    "    ax=ax, label='additional FP')\n",
    "\n",
    "ax.set_title('betrieb')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('# cycles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_labels(db, cycinfo, isdefect, '103_flap', 'maxslope', y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = plot_labels(db, cycinfo, isdefect, '103_flap', 'asym95_m0std1_split', y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'flap'\n",
    "_ct = nbct(db, '2020-02-27 22:56:52', nb=0, days=12)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_isd = ytest.loc[db].xs('103_flap', level='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_isd[(_isd.maxslope == 0) & (_isd.asym95_m0std1_split == 0)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'flap'\n",
    "_ct = nbct(db, '2020-06-03 20:00:21', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)\n",
    "isdefect.loc(db).se.loc[_ct, '103_flap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positives\n",
    "#### 102_flap\n",
    "- large, asymmetric amplitudes (periodic, thin peaks) in AT\n",
    "- unclear asymmetry in example in stand - threshold barely crossed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = '102_flap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_isd = ytest.loc[db].xs(ch, level='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_isd[(_isd.maxslope == 1) | (_isd.asym95_m0std1_split == 1)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = ch[-4:]\n",
    "_ct = nbct(db, '2020-07-22 01:06:31', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "axaf = check_af(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "isdefect.loc(db).se.loc[_ct, ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = ch[-4:]\n",
    "_ct = nbct(db, '2020-06-23 04:02:04', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "axaf = check_af(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "isdefect.loc(db).se.loc[_ct, ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 101_flap\n",
    "- asymmetric, thin peaks in AT, close to threshold\n",
    "- unclear asymmetry in stand, close to threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = '101_flap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_isd = ytest.loc[db].xs(ch, level='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_isd[(_isd.maxslope == 1) | (_isd.asym95_m0std1_split == 1)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = ch[-4:]\n",
    "_ct = nbct(db, '2020-06-16 22:03:56', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "axaf = check_af(cycinfo, db, _ct, _ori, blades=(1, 2))\n",
    "isdefect.loc(db).se.loc[_ct, ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 101_edge\n",
    "- larger negative amplitudes than positive amplitudes within normal period - only locally in splits; often close to threshold\n",
    "- unclear asymmetry in stand, close to threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = '101_edge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_isd = ytest.loc[db].xs(ch, level='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_isd[(_isd.maxslope == 1) | (_isd.asym95_m0std1_split == 1)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = ch[-4:]\n",
    "_ct = nbct(db, '2020-07-24 05:14:16', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)\n",
    "isdefect.loc(db).se.loc[_ct, ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = ch[-4:]\n",
    "_ct = nbct(db, '2020-06-18 14:12:21', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)\n",
    "isdefect.loc(db).se.loc[_ct, ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of metrics over true positives and negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels = pd.DataFrame({'true': ytrue}).unstack('channel').reorder_levels([1, 0], axis=1)\n",
    "truedefect = weadbs.SEData(_labels, cycinfo.st.loc[_labels.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = 'maxslope'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    metric_hist(cycinfo.loc(truedefect.st.index), _metric, isdefect=truedefect,\n",
    "                **histopts[_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric = 'asym95_m0std1_split'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    metric_hist(cycinfo.loc(truedefect.st.index), _metric, isdefect=truedefect,\n",
    "                **histopts[_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siemens Gamesa 1\n",
    "- blade 1, edge: one cycle at 2020-07-25 23:06:46 with partially missing at data leading to large jump when data starts - could be classified as defect, but is single case\n",
    "- blade 2, edge: low amplitude across whole time period\n",
    "    - potentially low-pass behaviour\n",
    "    - no clear defect - hard to detect\n",
    "- blade 2, flap: \"einfach defekt\" across whole time period\n",
    "    - mostly flat signal\n",
    "    - until about 2020-06-28 high-frequency oscillations appear to be normal, but low frequencies completely suppressed\n",
    "    - then until about 2020-07-20 14:10 high-frequency oscillations still appear to happen concurrently with other channels, but with much reduced amplitude\n",
    "    - from 2020-07-20 17:22:49 random, extreme jumps in AT signal, but only in betrieb\n",
    "    - should be detected by flat line detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_bc_t_03078'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('maxslope')\n",
    "axes[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('asym95_m0std1_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycinfo.loc(db).st.loc['2020-07-20 23'].index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'edge'\n",
    "_ct = nbct(db, '2020-07-25 23:06:46', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = isdefect.loc(isdefect.se.iloc[:, 0] >= 0).se.loc[db, :]\n",
    "\n",
    "ytrue = ytest.xs('maxslope', axis=1, level=1).applymap(lambda v: 0)\n",
    "#ytrue['102_edge'] = 1\n",
    "ytrue['102_flap'] = 1\n",
    "\n",
    "ytest = ytest.stack('channel')\n",
    "ytrue = ytrue.stack('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.concat(\n",
    "    [clf.BinScores(ytrue, ytest[metric]).to_series()\n",
    "     for metric in ytest.columns], axis=1, keys=ytest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmrblba_bc_t_02848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_bc_t_02848'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('maxslope')\n",
    "axes[0].set_yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('asym95_m0std1_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycinfo.loc(db).loc('2020-06-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'edge'\n",
    "_ct = nbct(db, '2020-06-27 18:29:30', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positives in V112 at max rotor speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_bc_t_01158'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('maxslope', by='wind_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP rates **at max rotor speed**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdefect.loc(db).select_st({'omega_mean': (0.205,)}).se.stack('channel').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP rates **below max rotor speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdefect.loc(db).select_st({'omega_mean': (0, 0.205)}).se.stack('channel').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmrblba_bc_t_01763_strain\n",
    "- RBL 3 flap ztw BCE101 einfach defekt, from 2020-06-18 - rare? as not in 300 sample\n",
    "- RBL 2 edge BCE101 zu geringer Signalpegel\n",
    "- RBL 2 flap BCE101 zu geringer Signalpegel, supposedly fixed on 2019-05-29, but still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'cmrblba_bc_t_01763_strain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('maxslope')\n",
    "axes[0].set_yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = cycinfo.loc(db).plot_se('asym95_m0std1_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ori = 'flap'\n",
    "_ct = nbct(db, '2020-06-20 19:44:16', nb=0, days=2)\n",
    "axesat = check_at(cycinfo, db, _ct, _ori)\n",
    "axaf = check_af(cycinfo, db, _ct, _ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weadbs.cdef_query(db, cycle='hour', columns=['ID'], where={'create_time': _ct}).loc[0, 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = csv.load_at_dir(db, _ct, 58965, oris=('edge', 'flap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym(tdata.astype(float), 0.95, norm='m0std1', split=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
